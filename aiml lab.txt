Progm 3
# Simple Probability Calculator
# Author: (You can write your name here)

def calculate_probability(favorable, total):
    """Calculate probability = favorable outcomes / total outcomes"""
    if total == 0:
        return 0
    return favorable / total

print("🎯 Simple Probability Calculator 🎯\n")
print("Choose an example:")
print("1. Using cards (Hearts, Diamonds, Clubs, Spades)")
print("2. Rolling a die (1 to 6)")
print("3. Tossing a coin (Heads or Tails)")

# Step 1: Ask user to choose
choice = input("\nEnter your choice (1-3): ").strip()

# Step 2: Set up the sample space
if choice == "1":
    sample_space = ["Hearts", "Diamonds", "Clubs", "Spades"]
    description = "Card suits"
elif choice == "2":
    sample_space = ["1", "2", "3", "4", "5", "6"]
    description = "Rolling a die"
elif choice == "3":
    sample_space = ["Heads", "Tails"]
    description = "Coin toss"
else:
    print("Invalid choice! Please restart the program.")
    exit()

# Step 3: Show sample space
total_outcomes = len(sample_space)
print(f"\n✅ Example selected: {description}")
print(f"Sample space (S): {sample_space}")
print(f"Total outcomes = {total_outcomes}\n")

# Step 4: Define an event
event_name = input("Enter a name for your event (e.g., Even, Red, Heads): ")
event_items = input(f"Enter outcomes for '{event_name}' (comma-separated): ")

# Keep only valid outcomes that are part of the sample space
event_outcomes = [x.strip() for x in event_items.split(",") if x.strip() in sample_space]

# Step 5: Calculate probability
favorable = len(event_outcomes)
probability = calculate_probability(favorable, total_outcomes)

# Step 6: Display result
print(f"\nEvent '{event_name}': {event_outcomes}")
print(f"n(E) = {favorable}")
print(f"P({event_name}) = {favorable}/{total_outcomes} = {probability:.2f}")

print("\n🎉 Program finished! Thanks for using the Probability Calculator.")
==================================================================================
Prgm 4
# Import required libraries
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import pandas as pd

# Step 1: Load the Iris dataset
iris = load_iris()

# Step 2: Create feature and target data
X = iris.data
y = iris.target

# Step 3: Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Create and train the KNN classifier
k = 5  # number of neighbors
knn = KNeighborsClassifier(n_neighbors=k)
knn.fit(X_train, y_train)

# Step 5: Make predictions
y_pred = knn.predict(X_test)

# Step 6: Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy * 100:.2f}%\n")


# Step 7: Display correct and wrong predictions
results = pd.DataFrame({
    'Actual': [iris.target_names[i] for i in y_test],
    'Predicted': [iris.target_names[i] for i in y_pred]
})

# Step 8: Separate correct and wrong predictions
correct = results[results['Actual'] == results['Predicted']]
wrong = results[results['Actual'] != results['Predicted']]

print("✅ Correct Predictions:")
print(correct.to_string(index=False))

print("\n❌ Wrong Predictions:")
print(wrong.to_string(index=False) if not wrong.empty else "None - all predictions correct!")
==================================================================================
Progm 5
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Step 1: Generate simple sample data
np.random.seed(42)
data1 = np.random.randn(100, 2) + np.array([2, 2])
data2 = np.random.randn(100, 2) + np.array([-2, -2])
data3 = np.random.randn(100, 2) + np.array([2, -2])
X = np.vstack([data1, data2, data3])

# Step 2: Plot BEFORE clustering
plt.figure(figsize=(12,5))

plt.subplot(1, 2, 1)
plt.scatter(X[:,0], X[:,1], color='blue',cmap='coolwarm')
plt.title("Before K-Means Clustering")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.grid(True)

# Step 3: Apply K-Means
k = 3
kmeans = KMeans(n_clusters=k, random_state=42)
labels = kmeans.fit_predict(X)
centroids = kmeans.cluster_centers_

# Step 4: Plot AFTER clustering
plt.subplot(1, 2, 2)
plt.scatter(X[:,0], X[:,1], c=labels, cmap='viridis')
plt.scatter(centroids[:,0], centroids[:,1], c='red', s=200, marker='X', label='Centroids')
plt.title("After K-Means Clustering")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# Step 5: Evaluate clustering quality
inertia = kmeans.inertia_
sil_score = silhouette_score(X, labels)

print(f"Inertia (Lower is better): {inertia:.2f}")
print(f"Silhouette Score (Closer to 1 is better): {sil_score:.4f}")
Progm 




